aspen:
  minimal_context: true

  inference_pipeline:
    - type: LoadImageFromFile
    - type: HmCrop
      keys: [img]
    - type: HmImageToTensor
      keys: [img]
    - type: HmResize
      img_scale: [1312, 480]
      keep_ratio: true
      interpolation: area
    - type: HmPad
      pad_val: 114.0
      size_divisor: 32
    - type: mmdet.PackTrackInputs
      meta_keys: [img_metas]

  video_out_pipeline:
    - type: HmConfigureScoreboard
    - type: HmCaptureScoreboard
      scoreboard_scale: GLOBAL.rink.scoreboard.scoreboard_scale
    - type: HmPerspectiveRotation
      pre_clip: true
    - type: HmCropToVideoFrame
    - type: HmRenderScoreboard
      image_labels: [img, end_zone_img]
    - type: HmUnsharpMask
      enabled: false
      image_label: img
    - type: HmImageOverlays
      watermark_config:
        image: images/sports_ai_watermark.png

  plugins:
    stitching:
      class: hmlib.aspen.plugins.stitching_plugin.StitchingPlugin
      depends: []
      enabled: GLOBAL.aspen.stitching.enabled
      params:
        pto_project_file: GLOBAL.aspen.stitching.pto_project_file
        dir_name: GLOBAL.aspen.stitching.dir_name
        blend_mode: GLOBAL.aspen.stitching.blend_mode
        max_blend_levels: GLOBAL.aspen.stitching.max_blend_levels
        auto_adjust_exposure: GLOBAL.aspen.stitching.auto_adjust_exposure
        python_blender: GLOBAL.aspen.stitching.python_blender
        minimize_blend: GLOBAL.aspen.stitching.minimize_blend
        dtype: GLOBAL.aspen.stitching.dtype
        no_cuda_streams: GLOBAL.aspen.stitching.no_cuda_streams
        post_stitch_rotate_degrees: GLOBAL.aspen.stitching.post_stitch_rotate_degrees
        left_color_pipeline: GLOBAL.aspen.left_stitch_pipeline
        right_color_pipeline: GLOBAL.aspen.right_stitch_pipeline
        capture_rgb_stats: GLOBAL.aspen.stitching.capture_rgb_stats
        max_output_width: GLOBAL.aspen.stitching.max_output_width

    image_prep:
      class: hmlib.aspen.plugins.image_prep_plugin.ImagePrepPlugin
      depends: [stitching]
      params: {}

    model_factory:
      class: hmlib.aspen.plugins.model_factory_plugin.ModelFactoryPlugin
      depends: []
      params:
        model_class: hmlib.models.end_to_end_plugin.HmEndToEnd
        # post_* pipelines not used for rink mask
        post_tracking_pipeline: []

    boundaries:
      class: hmlib.aspen.plugins.boundaries_plugin.BoundariesPlugin
      depends: [model_factory]
      params: {}

    pose_factory:
      class: hmlib.aspen.plugins.pose_factory_plugin.PoseInferencerFactoryPlugin
      depends: []
      params:
        pose_config: hmlib/config/models/body_2d_keypoint/rtmpose/coco/rtmpose-l_8xb256-420e_aic-coco-384x288.py
        pose_checkpoint: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmpose-l_simcc-aic-coco_pt-aic-coco_420e-384x288-97d6cb0f_20230228.pth
        show_progress: false

    pose:
      class: hmlib.aspen.plugins.pose_plugin.PosePlugin
      depends: [image_prep, pose_factory]
      params:
        plot_pose: GLOBAL.plot.plot_pose

    save_pose:
      class: hmlib.aspen.plugins.save_plugins.SavePosePlugin
      depends: [pose]
      params: {}

    pose_to_det:
      class: hmlib.aspen.plugins.pose_to_det_plugin.PoseToDetPlugin
      depends: [pose]
      params: {}

    save_detections:
      class: hmlib.aspen.plugins.save_plugins.SaveDetectionsPlugin
      depends: [pose_to_det]
      params: {}

    ice_config:
      class: hmlib.aspen.plugins.ice_rink_boundaries_plugins.IceRinkSegmConfigPlugin
      depends: [image_prep]
      params: {}

    ice_boundaries:
      class: hmlib.aspen.plugins.ice_rink_boundaries_plugins.IceRinkSegmBoundariesPlugin
      depends: [pose_to_det, ice_config]
      params:
        max_detections_in_mask: 50

    tracker:
      class: hmlib.aspen.plugins.tracker_plugin.TrackerPlugin
      depends: [pose_to_det, ice_boundaries, model_factory, boundaries]
      params: {}

    jersey_numbers:
      class: hmlib.aspen.plugins.jersey_koshkina_plugin.KoshkinaJerseyNumberPlugin
      depends: [tracker]
      params:
        # ROI selection: bbox (default), pose, or sam
        roi_mode: pose

        # Configure PARSeq STR (jersey-number pipeline)
        parseq_weights: "pretrained/parseq/jersey/hockey/epoch=3-step=95-val_accuracy=98.7903-val_NED=99.3952.ckpt"
        parseq_device: cuda
        # Legacy STR fields are ignored by this trunk but kept for compatibility
        str_backend: parseq
        # parseq_weights: /abs/path/to/parseq.ckpt   # optional; if omitted, tries pretrained
        # parseq_device: cuda                        # optional; defaults to image device

        # Legibility filtering
        legibility_enabled: true
        legibility_weights: pretrained/legibility_classifier/hockey/legibility_resnet34_hockey_20240201.pth
        legibility_threshold: 0.5

        # Optional: add a sleeve ROI when the pose looks side-on (orthogonal to camera)
        # side_view_enabled: true
        # side_view_shoulder_ratio_thresh: 0.22
        # side_view_vote_scale: 1.25

        # ReID occlusion/outlier removal
        reid_enabled: false
        reid_backend: resnet   # 'resnet' or 'centroid'
        reid_backbone: resnet34
        reid_threshold: 3.0
        # centroid_reid_path: /abs/path/to/centroid-reid  # optional; or set env HM_CENTROID_REID_PATH
        # centroid_reid_device: cuda

        # SAM refinement (optional; requires segment_anything)
        sam_enabled: false
        # roi_mode: sam
        # sam_checkpoint: /abs/path/to/sam_vit_b.pth
        # sam_model_type: vit_b
        # sam_device: cuda

        # OCR thresholds when using MMOCR
        det_thresh: 0.5
        rec_thresh: 0.8

    save_tracking:
      class: hmlib.aspen.plugins.save_plugins.SaveTrackingPlugin
      depends: [jersey_numbers, pose]
      params: {}

    postprocess:
      class: hmlib.aspen.plugins.postprocess_plugin.CamPostProcessPlugin
      depends: [jersey_numbers]
      params: {}
