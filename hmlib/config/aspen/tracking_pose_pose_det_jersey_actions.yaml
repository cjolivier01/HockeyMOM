aspen:
  minimal_context: true

  inference_pipeline:
    - type: LoadImageFromFile
    - type: HmCrop
      keys: [img]
      save_clipped_images: true
    - type: HmImageToTensor
      keys: [img]
    - type: HmResize
      img_scale: [1312, 480]
      keep_ratio: true
      interpolation: area
    - type: HmPad
      pad_val: 114.0
      size_divisor: 32
    - type: mmdet.PackTrackInputs
      meta_keys: [img_metas]

  video_out_pipeline:
    - type: HmConfigureScoreboard
    - type: HmCaptureScoreboard
    - type: HmPerspectiveRotation
      pre_clip: true
    - type: HmCropToVideoFrame
    - type: HmRenderScoreboard
      image_labels: [img, end_zone_img]
    - type: HmUnsharpMask
      enabled: false
      image_label: img
    - type: HmImageOverlays
      watermark_config:
        image: images/sports_ai_watermark.png

  trunks:
    image_prep:
      class: hmlib.aspen.trunks.image_prep.ImagePrepTrunk
      depends: []
      params: {}

    model_factory:
      class: hmlib.aspen.trunks.model_factory.ModelFactoryTrunk
      depends: []
      params:
        model_class: hmlib.models.end_to_end.HmEndToEnd
        # post_* pipelines not used for rink mask
        post_tracking_pipeline: []

    boundaries:
      class: hmlib.aspen.trunks.boundaries.BoundariesTrunk
      depends: [model_factory]
      params: {}

    pose_factory:
      class: hmlib.aspen.trunks.pose_factory.PoseInferencerFactoryTrunk
      depends: []
      params:
        pose_config: hmlib/config/models/body_2d_keypoint/rtmpose/coco/rtmpose-l_8xb256-420e_aic-coco-384x288.py
        pose_checkpoint: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmpose-l_simcc-aic-coco_pt-aic-coco_420e-384x288-97d6cb0f_20230228.pth
        show_progress: false

    pose:
      class: hmlib.aspen.trunks.pose.PoseTrunk
      depends: [image_prep, pose_factory]
      params: {}

    pose_to_det:
      class: hmlib.aspen.trunks.pose_to_det.PoseToDetTrunk
      depends: [pose]
      params: {}

    ice_config:
      class: hmlib.aspen.trunks.ice_rink_boundaries.IceRinkSegmConfigTrunk
      depends: [image_prep]
      params: {}

    ice_boundaries:
      class: hmlib.aspen.trunks.ice_rink_boundaries.IceRinkSegmBoundariesTrunk
      depends: [pose_to_det, ice_config]
      params: {}

    tracker:
      class: hmlib.aspen.trunks.tracker.TrackerTrunk
      depends: [pose_to_det, ice_boundaries, model_factory, boundaries]
      params: {}

    # New: MMAction2 action recognition from poses per tracked player
    action_factory:
      class: hmlib.aspen.trunks.action_factory.ActionRecognizerFactoryTrunk
      depends: []
      params:
        action_config: openmm/mmaction2/configs/skeleton/posec3d/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint.py
        action_checkpoint: https://download.openmmlab.com/mmaction/v1.0/skeleton/posec3d/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint/slowonly_r50_8xb16-u48-240e_ntu60-xsub-keypoint_20220815-38db104b.pth
        # Optional: label map (defaults to NTU60 label map if omitted)
        # label_map_path: openmm/mmaction2/tools/data/skeleton/label_map_ntu60.txt

    actions:
      class: hmlib.aspen.trunks.action_pose.ActionFromPoseTrunk
      depends: [tracker, action_factory]
      params:
        top_k: 3
        score_threshold: 0.0

    jersey_numbers:
      class: hmlib.aspen.trunks.jersey_pose.JerseyNumberFromPoseTrunk
      depends: [tracker]
      params: {}

    # Save outputs to dataframes (order matters so actions/jerseys are included)
    save_detections:
      class: hmlib.aspen.trunks.save.SaveDetectionsTrunk
      depends: [pose_to_det]
      params: {}

    save_pose:
      class: hmlib.aspen.trunks.save.SavePoseTrunk
      depends: [pose]
      params: {}

    save_tracking:
      class: hmlib.aspen.trunks.save.SaveTrackingTrunk
      depends: [actions]
      params: {}

    postprocess:
      class: hmlib.aspen.trunks.postprocess.CamPostProcessTrunk
      depends: [save_tracking, jersey_numbers]
      params: {}
